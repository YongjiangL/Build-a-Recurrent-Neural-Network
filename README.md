# Build-a-Recurrent-Neural-Network
Recurrent Neural Networks (RNN) are very effective for Natural Language Processing and other sequence tasks because they have "memory". They can read inputs x<t> (such as words) one at a time, and remember some information/context through the hidden layer activations that get passed from one time-step to the next. This allows a uni-directional RNN to take information from the past to process later inputs. A bidirection RNN can take context from both the past and the future.
refer: Deep Learning Specialization on Coursera(https://www.coursera.org/specializations/deep-learning)
